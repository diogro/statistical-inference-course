---
title: "Causal model building"
description: |
author: "Diogo Melo"
date: '2023-01-24'
output: 
    distill::distill_article
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# dagitty package

Much of the causal implications contained in DAGs can be analysed automatically. 
The dagitty package provides functions for this.

```{r}
if(!require("dagitty")) install.packages("dagitty")
library(dagitty)
```

# Remembering multiple regression

# Good controls

When fitting causal models, it is often necessary to add covariates to a linear model in order to correctly identify the effect of interest. This means running a multiple regression in which one of the coefficients is related to the causal path of interest, and the others are added to the model in order to block non-causal paths. Many of the examples in this tutorial are from [Cinelli, Carlos, Andrew Forney, and Judea Pearl. "A crash course in good and bad controls." Sociological Methods & Research (2021): 00491241221099552.](https://ftp.cs.ucla.edu/pub/stat_ser/r493.pdf)

For example, in the following DAGs, where X, Y and Z are observed, and U is unobserved:

![](../figures/DAGS/good_controls_1.png)

There is always a shared common cause between X and Y, and estimating the effect of X on Y requires blocking this non-causal path. The variable Z can be used as a covariate in all cases, even in the presence of the unobserved confound U.

Let's check this by simulating the DAG in model 2:

```{r}
N = 100
U = rnorm(N)
b_zu = 0.5
Z = rnorm(N, b_zu * U)
b_xz = 0.8
X = rnorm(N, b_xz * Z)
b_yu = 1
b_yx = 1
Y = rnorm(N, b_yu * U + b_yx * X)

lm(Y ~ X) |> coef() # Biased by non-causal path, effect of X is overestimated
lm(Y ~ X + Z) |> coef() # Unbiased, effect of X is correct and equal to b_yx
```


The same logic applies if the confound is mediated by another variable M:

![](../figures/DAGS/good_controls_2.png)

Z should be added as a covariate in all of these cases. 


__Question__: If we are interested in the effect of X on Y, could M also be added to the model? Explain.

__Exercise__: Choose one of these DAGs and run a simulation, explore the effect of adding Z or M as covariates.

## Pretty good controls

Some covariates can be added to a model not to avoid bias, but to increase precision. For example, in the following DAG:

```{r, out.height=100, out.width=100, echo=FALSE}
knitr::include_graphics("../figures/DAGS/pretty_good.png")
```

Adding Z as a covariate increases the precision of the estimate of the effect of X on Y.

Again, let's check using simulations:

```{r}
set.seed(2)
library(rethinking)
N = 200
X = rnorm(N)
Z = rnorm(N)
b_yx = 1
b_yz = 2
Y = rnorm(N, b_yx * X + b_yz * Z)

yx = lm(Y ~ X) |> extract.samples()
yxz = lm(Y ~ X + Z) |> extract.samples()
dens(yxz$X, lwd = 2, col = 2, xlim = c(0.4, 1.65), xlab = "b_yx")
dens(yx$X, lwd = 2, col = 1, add =TRUE)
```

This happens because adding the covariate removes part of the variation in Y that is not associated with X. 

__Question__: What if Z is a cause of X, not of Y. Would adding it to the regression help in this case?

# Bad controls

Two classes of bad controls are the posttreatment or overcontrol bias, and bias amplification. 

In the following DAGs, controlling on Z would lead to a understimate of the effect of X on Y.

```{r, out.height=150, out.width=550, echo=FALSE}
knitr::include_graphics("../figures/DAGS/overcontrol.png")
```

In the following case, controlling on Z would lead to an increase in the bias caused by the unobserved variable U.

```{r, out.height=150, out.width=210, echo=FALSE}
knitr::include_graphics("../figures/DAGS/bias_amplification.png")
```

__Exercise__: Simulate the bias amplification example and check the effect of including the Z variable in the model.

## AIC and significance won't help you

To explore the effect of a bad control variable, let's simulate a collider:

```{r}
# DAG : X -> Z <- Y
N = 200
X = rnorm(N)
Y = rnorm(N)
Z = rnorm(N, Y + X)

m1 = lm(Y~X)   # Correct model
m2 = lm(Y~X+Z) # Model including the collider
```

First, let's look at the significance of the variables in both models:

```{r}
summary(m1)
summary(m2)
```

Not including Z gives the correct estimate of no effect of X on Y, but the model including Z tells us that both X and Z have significant effects on Y. Why is this?

Many researchers would interpret the significant results in model 2 as evidence that both X and Z affect Y, don't make this mistake! Statistical models are blind to causes, they only capture associations.

How about AIC? Would model comparison identify the correct model?

```{r}
library(bbmle)
AICctab(m1, m2, mnames = c("Correct", "Biased"),
        base=TRUE, weights = TRUE, nobs = N)
```

The biased model is also selected by the AIC. This is not surprising, as the inclusion of the collider increases the available information about Y, and so makes better predictions.

__The only way to identify the possible bias is having a clear scientific model.__

# Practice DAGs

For each of the following DAGs form the rethinking book, write down the correct models for estimating the total causal influence of X on Y:

```{r, out.height=285, out.width=400, echo=FALSE}
knitr::include_graphics("../figures/dags_6M3.png")
```

You can check your answers using the dagitty package or the [online interface](http://www.dagitty.net/dags.html). Here is an example:

```{r}
library(dagitty)
dag1 = dagitty('dag { X -> Y Z -> X Z -> Y A -> Z A -> Y}')

# Plotting the dag, we can use coordinates to place the nodes in the desired position
coordinates( dag1 ) <-
    list( x=c(X = 0, Y = 2, Z = 1, A = 2),
          y=c(X = 0, Y = 0, Z = -1, A = -1) )
plot(dag1)

# get all paths
paths(dag1, from = "X", to = "Y")

# get the correct adjustment set
adjustmentSets(dag1, exposure = "X", outcome = "Y")
```

